{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "395936a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"29500\"\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/data2/zzd/rl_llm/verl\")\n",
    "\n",
    "import torch\n",
    "from megatron.core import parallel_state as mpu\n",
    "\n",
    "torch.distributed.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "mpu.initialize_model_parallel(\n",
    "    tensor_model_parallel_size=1,\n",
    "    pipeline_model_parallel_size=1,\n",
    "    virtual_pipeline_model_parallel_size=None,\n",
    "    pipeline_model_parallel_split_rank=None,\n",
    "    use_sharp=False,\n",
    "    context_parallel_size=1,\n",
    "    expert_model_parallel_size=1,\n",
    "    nccl_communicator_config_path=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ac0ac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from verl.models.mcore.util import preprocess_packed_seqs, postprocess_packed_seqs\n",
    "\n",
    "batch_size = 2\n",
    "seq_len = 32\n",
    "\n",
    "input_ids = torch.randint(0, 100, (batch_size, seq_len))\n",
    "attention_mask = torch.ones((batch_size, seq_len), dtype=torch.bool)\n",
    "attention_mask[:, -20:] = False  \n",
    "\n",
    "input_ids_pad, packed_seq_params = preprocess_packed_seqs(input_ids, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9dd49d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[60, 88, 81, 31, 50,  4, 34, 63,  2, 78, 59, 49, 61, 52, 17,  0, 54, 73,\n",
      "          6, 23, 80, 85, 12, 41, 37, 50, 76, 29, 15, 55, 99, 59],\n",
      "        [52, 84, 62, 95, 14, 96, 55,  8, 28, 97, 27, 49, 34, 43, 50, 71,  8, 48,\n",
      "         98, 36, 10, 71, 11, 94, 45, 77,  5,  3, 93, 54, 20, 32]])\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False]])\n",
      "tensor([[60, 88, 81, 31, 50,  4, 34, 63,  2, 78, 59, 49, 52, 84, 62, 95, 14, 96,\n",
      "         55,  8, 28, 97, 27, 49]])\n",
      "PackedSeqParams(qkv_format='thd', cu_seqlens_q=tensor([ 0, 12, 24], dtype=torch.int32), cu_seqlens_kv=tensor([ 0, 12, 24], dtype=torch.int32), cu_seqlens_q_padded=tensor([ 0, 12, 24], dtype=torch.int32), cu_seqlens_kv_padded=tensor([ 0, 12, 24], dtype=torch.int32), max_seqlen_q=12, max_seqlen_kv=12)\n"
     ]
    }
   ],
   "source": [
    "print(input_ids)\n",
    "print(attention_mask)\n",
    "print(input_ids_pad)\n",
    "print(packed_seq_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
