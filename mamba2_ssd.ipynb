{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  torch.Size([3, 2, 64, 4, 256])\n",
      "B shape:  torch.Size([3, 2, 64, 4, 64])\n",
      "C shape:  torch.Size([3, 2, 64, 4, 64])\n",
      "A shape:  torch.Size([3, 4, 2, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "# X: (batch, length, n_heads, d_head)\n",
    "# A: (batch, length, n_heads)\n",
    "# B: (batch, length, n_heads, d_state)\n",
    "# C: (batch, length, n_heads, d_state)\n",
    "batch, length, n_heads, d_head = 3, 128, 4, 256\n",
    "block_len = 64\n",
    "d_state = 64\n",
    "initial_states = None\n",
    "X = torch.randn((batch, length, n_heads, d_head), dtype=torch.float32)\n",
    "A = torch.randn((batch, length, n_heads), dtype=torch.float32)\n",
    "B = torch.randn((batch, length, n_heads, d_state), dtype=torch.float32)\n",
    "C = torch.randn((batch, length, n_heads, d_state), dtype=torch.float32)\n",
    "\n",
    "# Rearrange into blocks/chunks\n",
    "X, A, B, C = [rearrange(x, \"b (c l) ... -> b c l ...\", l=block_len) for x in (X, A, B, C)]\n",
    "print(\"X shape: \", X.shape)\n",
    "print(\"B shape: \", B.shape)\n",
    "print(\"C shape: \", C.shape)\n",
    "\n",
    "A = rearrange(A, \"b c l h -> b h c l\")\n",
    "print(\"A shape: \", A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_cumsum shape:  torch.Size([3, 4, 2, 64])\n",
      "tensor([[-0.2658,  0.2051, -0.4677,  0.1695,  1.1255,  0.6326,  2.0853,  1.0546,\n",
      "         -0.0799, -1.0708, -1.2451, -1.1371, -1.5578, -3.3396, -3.1794, -2.2924,\n",
      "         -1.1573, -0.0832,  0.2795, -0.0132, -0.5667, -0.5211, -0.5288, -2.2874,\n",
      "         -1.0053, -0.3439,  1.1854,  0.6855, -0.0088, -1.6028, -2.5258, -2.5608,\n",
      "         -2.8232, -3.5375, -3.0490, -2.8024, -1.8804, -1.6589, -0.3597, -3.0049,\n",
      "         -3.0880, -1.7377, -0.7670, -1.5339, -2.3543, -2.1628, -1.9823, -0.9725,\n",
      "         -0.2307, -0.5601, -3.2543, -0.9201,  0.1051, -0.1104, -0.4800, -0.4885,\n",
      "          0.2217, -1.1623, -0.6456, -0.5058, -0.3892,  0.5867, -0.6275, -2.5660],\n",
      "        [-0.2748,  0.2375,  0.3691,  1.5900,  1.8836,  1.0119, -1.2858, -4.3879,\n",
      "         -3.6671, -2.6230, -0.4432,  1.3762,  1.2834,  1.2889,  1.9674,  2.2748,\n",
      "          1.0832,  0.5214,  0.3608,  0.5663, -1.5273, -0.8515,  0.4281,  0.8482,\n",
      "         -1.3273, -2.0056, -1.8443, -2.0875, -1.4093, -2.3229, -2.8099, -0.9775,\n",
      "         -1.5749, -2.4707, -1.0007, -1.2264, -1.1913, -0.8919, -2.0950, -0.8441,\n",
      "         -0.8114,  1.4995,  3.3490,  3.1396,  5.6675,  6.1537,  4.9307,  5.9541,\n",
      "          5.0350,  4.7268,  4.3694,  4.0773,  4.6385,  3.0739,  4.8262,  6.3020,\n",
      "          6.5707,  5.9844,  6.1685,  6.8139,  7.9757,  6.5351,  5.3688,  5.3442]])\n"
     ]
    }
   ],
   "source": [
    "A_cumsum = torch.cumsum(A, dim=-1)\n",
    "print(\"A_cumsum shape: \", A_cumsum.shape)\n",
    "print(A_cumsum[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segsum(x):\n",
    "    \"\"\"More stable segment sum calculation.\"\"\"\n",
    "    T = x.size(-1)\n",
    "    x = repeat(x, \"... d -> ... d e\", e=T)\n",
    "    mask = torch.tril(torch.ones(T, T, device=x.device, dtype=bool), diagonal=-1)\n",
    "    x = x.masked_fill(~mask, 0)\n",
    "    x_segsum = torch.cumsum(x, dim=-2)\n",
    "    mask = torch.tril(torch.ones(T, T, device=x.device, dtype=bool), diagonal=0)\n",
    "    x_segsum = x_segsum.masked_fill(~mask, -torch.inf)\n",
    "    return x_segsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L shape:  torch.Size([3, 4, 2, 64, 64])\n",
      "Y_diag shape:  torch.Size([3, 2, 64, 4, 256])\n",
      "tensor([[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.6014, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.8172, 0.5103, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [2.3456, 1.4647, 2.8702,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.6965, 0.4349, 0.8523,  ..., 0.2969, 1.0000, 0.0000],\n",
      "        [0.1002, 0.0626, 0.1227,  ..., 0.0427, 0.1439, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    " # 1. Compute the output for each intra-chunk (diagonal blocks)\n",
    "L = torch.exp(segsum(A))\n",
    "Y_diag  = torch.einsum(\"bclhn,bcshn,bhcls,bcshp->bclhp\", C, B, L, X)  ## orange\n",
    "print(\"L shape: \", L.shape)\n",
    "print(\"Y_diag shape: \", Y_diag.shape)\n",
    "print(L[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decay_states shape:  torch.Size([3, 4, 2, 64])\n",
      "states shape:  torch.Size([3, 2, 4, 256, 64])\n"
     ]
    }
   ],
   "source": [
    "# 2. Compute the state for each intra-chunk\n",
    "# (right term of low-rank factorization of off-diagonal blocks; B terms)\n",
    "decay_states = torch.exp((A_cumsum[:, :, :, -1:] - A_cumsum))\n",
    "states = torch.einsum(\"bclhn,bhcl,bclhp->bchpn\", B, decay_states, X)  ## green\n",
    "print(\"decay_states shape: \", decay_states.shape)\n",
    "print(\"states shape: \", states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states shape:  torch.Size([3, 2, 4, 256, 64])\n",
      "final_state shape:  torch.Size([3, 4, 256, 64])\n"
     ]
    }
   ],
   "source": [
    "# 3. Compute the inter-chunk SSM recurrence; produces correct SSM states at chunk boundaries\n",
    "# (middle term of factorization of off-diag blocks; A terms)\n",
    "if initial_states is None:\n",
    "    initial_states = torch.zeros_like(states[:, :1])\n",
    "states = torch.cat([initial_states, states], dim=1)\n",
    "decay_chunk = torch.exp(segsum(F.pad(A_cumsum[:, :, :, -1], (1, 0))))\n",
    "new_states = torch.einsum(\"bhzc,bchpn->bzhpn\", decay_chunk, states)  ## yellow\n",
    "states, final_state = new_states[:, :-1], new_states[:, -1]\n",
    "print(\"states shape: \", states.shape)\n",
    "print(\"final_state shape: \", final_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_decay_out shape:  torch.Size([3, 4, 2, 64])\n",
      "Y_off shape:  torch.Size([3, 2, 64, 4, 256])\n",
      "Y Shape:  torch.Size([3, 128, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "# 4. Compute state -> output conversion per chunk\n",
    "# (left term of low-rank factorization of off-diagonal blocks; C terms)\n",
    "state_decay_out = torch.exp(A_cumsum)   ## blue\n",
    "Y_off = torch.einsum('bclhn,bchpn,bhcl->bclhp', C, states, state_decay_out)\n",
    "\n",
    "# Add output of intra-chunk and inter-chunk terms (diagonal and off-diagonal blocks)\n",
    "Y = rearrange(Y_diag+Y_off, \"b c l h p -> b (c l) h p\")\n",
    "\n",
    "print(\"state_decay_out shape: \", state_decay_out.shape)\n",
    "print(\"Y_off shape: \", Y_off.shape)\n",
    "print(\"Y Shape: \", Y.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
